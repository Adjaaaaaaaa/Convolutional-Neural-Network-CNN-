# ğŸ©º DÃ©tection de la Pneumonie sur Radiographies Thoraciques par Deep Learning

Ce projet prÃ©sente une **preuve de concept (proof of concept)** pour un systÃ¨me de classification binaire de radios thoraciques visant Ã  dÃ©tecter des cas de **pneumonie**. Le modÃ¨le repose sur le **transfert dâ€™apprentissage (transfer learning)** Ã  partir de rÃ©seaux de neurones convolutifs (CNN) prÃ©entraÃ®nÃ©s, adaptÃ©s Ã  la tÃ¢che de classification mÃ©dicale.

Le pipeline couvre lâ€™ensemble du traitement : **prÃ©paration des donnÃ©es**, **entraÃ®nement**, **Ã©valuation**, et **suivi MLOps** avec MLflow.

Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre de la formation "DÃ©veloppeur en Intelligence Artificielle" dispensÃ©e par Simplon.co.

---

## ğŸ“¦ DonnÃ©es

Le dataset utilisÃ© est le **Chest X-Ray Pneumonia**, accessible ici :  
ğŸ”— https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia

ğŸ“Œ **Remarque importante :**  
Le dossier `val` dâ€™origine ne contient que **16 images**, ce qui est **insuffisant pour une validation fiable** pendant l'entraÃ®nement.  
ğŸ‘‰ Pour y remÃ©dier, les rÃ©pertoires `val` et `test` ont Ã©tÃ© inversÃ©s :  
- lâ€™ancien **test** est utilisÃ© comme **validation**,  
- lâ€™ancien **val** devient le **jeu de test final**, plus petit mais indÃ©pendant.

---

## ğŸ§  ModÃ¨les testÃ©s & stratÃ©gie

Trois modÃ¨les CNN ont Ã©tÃ© comparÃ©s dans une optique de transfert learning :

| ModÃ¨le       | Type                  | Finetuning       | Justification |
|--------------|-----------------------|------------------|---------------|
| **VGG16**     | Architecture classique | Non (couches gelÃ©es) | Baseline pÃ©dagogique |
| **ResNet50**  | Connexions rÃ©siduelles | Oui (dÃ©gel des derniÃ¨res couches) | Robuste, souvent utilisÃ© en clinique |
| **DenseNet121** | Connexions denses     | Oui (finetuning partiel) | Excellente gÃ©nÃ©ralisation en imagerie mÃ©dicale |

Les modÃ¨les **ResNet50** et **DenseNet121** ont Ã©tÃ© partiellement **dÃ©congelÃ©s (fine-tuning)** pour permettre au rÃ©seau dâ€™apprendre des **caractÃ©ristiques spÃ©cifiques aux radios mÃ©dicales**, au-delÃ  des reprÃ©sentations ImageNet.

ğŸ”¬ **RÃ©fÃ©rence utile :**  
ğŸ“„ [CEUR Workshop â€“ Paper 160](https://ceur-ws.org/Vol-3740/paper-160.pdf) dÃ©montre lâ€™efficacitÃ© de DenseNet et ResNet pour la classification de maladies respiratoires sur imagerie thoracique.

---
## ğŸ§© PrÃ©sentation des modÃ¨les CNN

### ğŸ“‰ VGG16

VGG16 est une architecture de rÃ©seau de neurones convolutifs dÃ©veloppÃ©e par lâ€™Ã©quipe dâ€™Oxford Visual Geometry 
Group (VGG). Elle se caractÃ©rise par :

- Une **structure simple et uniforme** : empilement de couches convolutionnelles 3x3 avec ReLU, suivies de 
max-pooling.
- **16 couches profondes** (dâ€™oÃ¹ le nom VGG16), incluant 13 convolutions et 3 couches fully connected.

Elle a Ã©tÃ© largement utilisÃ©e comme **modÃ¨le de rÃ©fÃ©rence (baseline)** en vision par ordinateur.

**Avantages clÃ©s :**
- Facile Ã  comprendre et Ã  implÃ©menter.
- TrÃ¨s utilisÃ©e dans les travaux pÃ©dagogiques.
- Offre de bonnes performances sur des tÃ¢ches simples.

**Limites :**
- Plus lourde en nombre de paramÃ¨tres.
- Moins efficace sur des tÃ¢ches complexes ou spÃ©cifiques (comme lâ€™imagerie mÃ©dicale).
- Moins adaptÃ©e Ã  des contextes oÃ¹ la gÃ©nÃ©ralisation fine est nÃ©cessaire.

### ğŸ§¬ DenseNet121

DenseNet (Dense Convolutional Network) est une architecture introduite pour amÃ©liorer le **flux dâ€™information 
entre les couches** dâ€™un rÃ©seau profond.  
Dans DenseNet121 :

- Chaque couche est **connectÃ©e Ã  toutes les couches suivantes**, ce qui permet une **meilleure rÃ©utilisation 
des caractÃ©ristiques** et une **rÃ©duction du surapprentissage**.
- Moins de paramÃ¨tres que dâ€™autres architectures classiques Ã  profondeur Ã©quivalente.
- TrÃ¨s adaptÃ© aux tÃ¢ches mÃ©dicales, car il extrait des **caractÃ©ristiques fines** pertinentes pour lâ€™imagerie.

**Avantages clÃ©s :**
- TrÃ¨s bonne **propagation du gradient**.
- Plus efficace avec **moins de donnÃ©es**.
- UtilisÃ© dans de nombreuses Ã©tudes en imagerie mÃ©dicale.

### ğŸ”— ResNet50

ResNet (Residual Network) introduit le concept de **connexions rÃ©siduelles** ou "skip connections", qui 
permettent de **sauter une ou plusieurs couches** pendant lâ€™entraÃ®nement.

- ResNet50 contient 50 couches profondes.
- Ces connexions permettent dâ€™**Ã©viter le problÃ¨me de dÃ©gradation** dans les rÃ©seaux trÃ¨s profonds (oÃ¹ les 
performances empirent Ã  mesure que le rÃ©seau s'approfondit).
- TrÃ¨s robuste et utilisÃ© comme **standard dans les applications industrielles et mÃ©dicales**.

**Avantages clÃ©s :**
- Permet des rÃ©seaux trÃ¨s profonds sans perte de performance.
- TrÃ¨s bon compromis entre performance et complexitÃ©.
- Architecture Ã©prouvÃ©e dans des contextes rÃ©els.

---

## ğŸ–¼ï¸ Exploration du dataset
* Il y a prÃ¨s de 3 fois plus dâ€™images de patients atteints de pneumonie que dâ€™images normales.
* Ce dÃ©sÃ©quilibre peut amener le modÃ¨le Ã  prÃ©dire la classe majoritaire, ici "PNEUMONIA", simplement parce que 
câ€™est statistiquement plus frÃ©quent.
* Le fait dâ€™avoir plus dâ€™images pour la pneumonie permet au modÃ¨le de mieux apprendre ses diffÃ©rentes manifestations visuelles.
* Les radios prÃ©sentent une variabilitÃ© importante selon les cas, soulignant lâ€™intÃ©rÃªt dâ€™un modÃ¨le capable dâ€™en 
extraire des **caractÃ©ristiques discriminantes robustes**.


ğŸ¯ Implications pour lâ€™apprentissage
* Risque : un modÃ¨le qui atteint 85% d'accuracy pourrait simplement toujours prÃ©dire "PNEUMONIA".
* ConsÃ©quence clinique : des faux positifs peuvent Ãªtre tolÃ©rÃ©s (mieux vaut suspecter une pneumonie par erreur que de la rater), mais les faux nÃ©gatifs (cas de pneumonie classÃ©s "NORMAL") sont dangereux.

![ex1](images/classes.png) 
![ex2](images/exemples.png) 


---

## âš™ï¸ DÃ©marche de modÃ©lisation

1. **PrÃ©traitement :** redimensionnement (224x224 ,taille standard pour les modÃ¨les ImageNet), normalisation.
2. **Transfert learning :**
   - Phase 1 : entraÃ®nement sur des couches gelÃ©es.
   - Phase 2 : **finetuning** des derniÃ¨res couches pour ResNet50/DenseNet121.
3. **Ã‰valuation :**
   - Accuracy, Loss, ROC-AUC, matrice de confusion.
4. **Suivi MLOps :**
   - Utilisation de **MLflow** pour tracer chaque expÃ©rience.

---

## ğŸ“ˆ Comparaison des rÃ©sultats

| ModÃ¨le       | Accuracy Test | AUC    | Observations |
|--------------|----------------|--------|--------------|
| **VGG16**     | 85%            | 0.94   | Overfitting lÃ©ger, bon rappel, mais prÃ©cision sur classe "normal" Ã  amÃ©liorer |
| **ResNet50**  | 79%            | 0.83   | TrÃ¨s bon Ã©quilibre prÃ©cision/rappel |
| **DenseNet121** | **94%**      | **0.97** | Meilleure gÃ©nÃ©ralisation, surtout avec fine-tuning |

---


Les courbes ci-dessous montrent la progression de lâ€™**accuracy**, de la **loss** et de la **matrice de confusion** sur les ensembles d'entraÃ®nement et de validation pour chaque modÃ¨le :
### ğŸ“‰ VGG16

 ![Accuracy Curve](images/courbes_vgg16.png)
 ![Confusion matrix](images/matrice_vgg16.png)

### ğŸ”— ResNet50
 ![Accuracy Curve](images/courbes_resnet50.png)
 ![Confusion matrix](images/matrice_resnet50.png)

### ğŸ§¬ DenseNet121
 ![Accuracy Curve](images/courbes_densenet121.png)
 ![Confusion matrix](images/matrice_densenet121.png)

âœ… DenseNet121 se distingue par un apprentissage stable et des performances fiables, avec de meilleurs rÃ©sultats sur les mÃ©triques dâ€™Ã©valuation, mÃªme lorsque le jeu de test est limitÃ©.

ğŸ‘‰ Des notebooks sÃ©parÃ©s sont disponibles pour chaque modÃ¨le testÃ© (VGG16, ResNet50, DenseNet121).
Chacun prÃ©sente en dÃ©tail les Ã©tapes spÃ©cifiques d'entraÃ®nement, les performances obtenues, les visualisations de mÃ©triques et les particularitÃ©s du fine-tuning.

ğŸ” Consulte-les pour approfondir l'analyse de chaque modÃ¨le.

---

## ğŸ§° Suivi MLOps avec MLflow

Un suivi rigoureux des expÃ©riences a Ã©tÃ© mis en place avec **MLflow** :

- **Tracking automatique** (metrics, modÃ¨les)
- **Comparaison multi-modÃ¨les** sur lâ€™interface Web

ğŸ“¸ Lâ€™interface MLflow :

![MLflow UI](images/mlflow_ui.png)

---

## 7ï¸âƒ£ Conclusion & perspectives

ğŸ¯ Ce projet montre qu'un **prototype basÃ© sur le transfert learning** peut fournir des rÃ©sultats prometteurs pour la dÃ©tection automatisÃ©e de pneumonie sur radios thoraciques.

ğŸ‘‰ DenseNet121, couplÃ© Ã  un finetuning partiel, offre les **meilleures performances** parmi les modÃ¨les testÃ©s.

ğŸ”„ **Prochaines Ã©tapes :**
- IntÃ©grer d'autres mÃ©triques orientÃ©es mÃ©dical (sensibilitÃ©, spÃ©cificitÃ©).
- Tester sur un dataset plus diversifiÃ©.
- Ajouter une interface utilisateur pour test clinique.
- DÃ©ployer le modÃ¨le via API (Flask/FastAPI).


## ğŸ“‚ Structure du projet
```plaintext
ğŸ“ data/chest_xray/
â”œâ”€â”€ train/
â”œâ”€â”€ val/              # (utilisÃ© comme test final)
â””â”€â”€ test/             # (utilisÃ© comme validation)
ğŸ“œ VGG16.ipynb
ğŸ“œ ResNet50.ipynb
ğŸ“œ DenseNet121.ipynb
ğŸ“œ README.md
ğŸ“œ requirements.txt
ğŸ“ images/
